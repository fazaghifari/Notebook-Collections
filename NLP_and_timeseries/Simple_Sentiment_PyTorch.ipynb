{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Simple Sentiment_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazaghifari/Notebook-Collections/blob/master/NLP_and_timeseries/Simple_Sentiment_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG0E51JhMs0W",
        "colab_type": "text"
      },
      "source": [
        "## Simple Sentiment Analysis with LSTM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyOCh14tNX1c",
        "colab_type": "text"
      },
      "source": [
        "#### Install PyTorch-NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOEn81fnNW82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7d945dba-6817-4556-d4c0-0d31115b4500"
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QarOYyVgNYN9",
        "colab_type": "text"
      },
      "source": [
        "Import Stuffs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_KrEYuYLY1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9dbc9f53-a378-4156-8681-80759536257e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import time\n",
        "import numpy as np\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    print(f'Device name = {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Device name = Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n-6W5NtMs0X",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Load in and visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRI3Kb-fc0U9",
        "colab_type": "code",
        "outputId": "6ae83743-2fc5-4f60-b05b-69d2edbf69fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6BYm6sQdgOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "file1 = 'reviews.txt'\n",
        "file2 = 'labels.txt'\n",
        "folder = '/content/drive/My Drive/datasets/sentiment_class/'\n",
        "path1 = os.path.join(folder,file1)\n",
        "path2 = os.path.join(folder,file2)\n",
        "# read data from text files\n",
        "with open(path1, 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open(path2, 'r') as f:\n",
        "    labels = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnsRTxHMMs0e",
        "colab_type": "code",
        "outputId": "2f296790-7a13-4d28-ea83-1561124cc4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "print(reviews[:2000])\n",
        "print()\n",
        "print(labels[:26])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \n",
            "homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y\n",
            "\n",
            "positive\n",
            "negative\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl1pVHyQMs0i",
        "colab_type": "text"
      },
      "source": [
        "### Data cleaning\n",
        "\n",
        "In this step, all punctuations in the sentences are removed because in this case punctuation won't make much difference. Then, the whole text is splitted into list of sentences based on '\\n'. Also, the labels is converted into 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Hs1wppMs0j",
        "colab_type": "code",
        "outputId": "44639443-ed3b-4a97-ca57-c6eba359c117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "print(punctuation)\n",
        "\n",
        "# get rid of punctuation\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "sentences = all_text.split('\\n') # Split text to list of sentences\n",
        "all_text = ' '.join(sentences)\n",
        "\n",
        "# Convert labels to 0 and 1\n",
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])\n",
        "print(len(sentences))\n",
        "print(len(encoded_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "25000\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OarvNQNYMs0r",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize Sentence\n",
        "\n",
        "PyTorch-NLP package is used to tokenize the words. Compared to standard PyTorch text, this tools is easier to use and more straightforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqfk8LEUQGVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "max_length = 200\n",
        "split_frac = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfPlyAI5Yf1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    ## implement function\n",
        "    \n",
        "    features=np.zeros((len(reviews_ints), seq_length))\n",
        "    for ii, content in enumerate(reviews_ints):\n",
        "        limit = len(content) if len(content) <= seq_length else seq_length\n",
        "        features[ii, :limit] = content[:seq_length]\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usd3LiKIMs0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchnlp.encoders.text import StaticTokenizerEncoder\n",
        "\n",
        "tokenizer = StaticTokenizerEncoder(sentences)\n",
        "sequences = [tokenizer.encode(sentence) for sentence in sentences]\n",
        "padded = pad_features(sequences, max_length)\n",
        "word_index = {word:ii for ii,word in enumerate(tokenizer.vocab)}\n",
        "split = int(split_frac * len(sentences))\n",
        "\n",
        "training_sequences = padded[0:split]\n",
        "val_sequences = padded[split:len(sentences)]\n",
        "training_labels = encoded_labels[0:split]\n",
        "val_labels = encoded_labels[split:len(sentences)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBCLyBjGZbpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "bceda092-d5d5-42aa-afab-765e8dea0ffd"
      },
      "source": [
        "print(tokenizer.vocab_size)\n",
        "print(word_index['i'])\n",
        "print(training_sequences.shape)\n",
        "print(training_labels.shape)\n",
        "print(training_sequences[:30,64:74])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74077\n",
            "62\n",
            "(20000, 200)\n",
            "(20000,)\n",
            "[[  56.   14.   57.   58.   59.   60.   32.   56.   14.   61.]\n",
            " [ 137.   14.  138.  139.  140.  114.  133.   14.  141.  142.]\n",
            " [ 204.   33.  205.  206.   14.  207.  208.  170.  198.  209.]\n",
            " [ 382.  177.  383.  384.   14.  355.    7.  385.  386.  120.]\n",
            " [ 234.  674.  675.   62.   79.    8.  673.  248.  553.  467.]\n",
            " [  14.  723.   62.  131.  338.   95.  339.  216.  216.  177.]\n",
            " [ 301.   64.   33.  776.   35.  133.   28.    8.   96.   21.]\n",
            " [ 809.   48.  154.  800.  392.  193.  131.  810.  528.   64.]\n",
            " [  14.  846.   33.  252.  469.  177.   59.   28.   59.  346.]\n",
            " [ 872.  652.  873.   56.   36.  874.   64.  875.  876.  877.]\n",
            " [ 260. 1010.  216.  216.  373. 1011. 1012. 1013.   64. 1014.]\n",
            " [1062.   28. 1063.  830.  177.   14. 1064. 1065. 1066.  453.]\n",
            " [1094. 1095.  154.   64.  772. 1096.  154. 1097.   33. 1098.]\n",
            " [  13.   14.  988.   56.  505. 1129.  614.   38.   14.   15.]\n",
            " [  36. 1235. 1236.  216.  216.  154.  814.  139. 1237. 1238.]\n",
            " [ 433.  701.  107.  627.   11.  284.  116. 1336. 1337. 1338.]\n",
            " [ 216.   28.   14. 1380. 1381.  831. 1382. 1210.  150. 1211.]\n",
            " [1490. 1491.  153. 1119.    0.    0.    0.    0.    0.    0.]\n",
            " [1474. 1509.   64.    8. 1510. 1511. 1512.    7. 1513.  260.]\n",
            " [  89.  346. 1575. 1211.  101.  791.  743.   47.  864.   11.]\n",
            " [ 216.  216.  105.  131.   14.   50. 1617.   56. 1618.  993.]\n",
            " [  47.  239. 1674. 1675.   33.   14. 1676. 1677.   56.   14.]\n",
            " [ 676.    7. 1292.  859.   62.  373.  471.  761.   14. 1736.]\n",
            " [ 338.   95. 1058. 1395.  120. 1745.  551.  177.  209.  154.]\n",
            " [   7.   14. 1036.   56.   14.  347. 1781.   14. 1040. 1782.]\n",
            " [ 619. 1846.  700. 1847.  883.  216.  216.   62.  471.  877.]\n",
            " [1857.   64.  178.  950.  433.   14. 1858.  791.    7.  725.]\n",
            " [1889.  526.   35.   36.  761.  611.   11.    7.  216.  216.]\n",
            " [  11.    7. 1037.   82.   56.   14. 1858.  839.   35.  468.]\n",
            " [1921.   62.  131. 1922.   28. 1923. 1924. 1667.  346.  700.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-rD3wnK7zuA",
        "colab_type": "text"
      },
      "source": [
        "### Download Embedding Layer Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZkQ3kLkaWEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "ac9160f7-a9ad-4eff-99a6-53650b53ca13"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d terenceliu4444/glove6b100dtxt\n",
        "!unzip glove6b100dtxt.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "glove6b100dtxt.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  glove6b100dtxt.zip\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etsjNPEfbLIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = {};\n",
        "with open('glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        values = line.split();\n",
        "        word = values[0];\n",
        "        coefs = np.asarray(values[1:], dtype='float32');\n",
        "        embeddings_index[word] = coefs;\n",
        "\n",
        "embeddings_matrix = np.zeros((tokenizer.vocab_size, embedding_dim));\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word);\n",
        "    if embedding_vector is not None:\n",
        "        embeddings_matrix[i] = embedding_vector;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajMQ6zcbbf_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b954e060-7b27-4e73-d8cc-959a70e5e2f0"
      },
      "source": [
        "print(embeddings_matrix.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(74077, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4790ZnYrIjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d3b478f-5297-4afc-8c01-5275cbc3882a"
      },
      "source": [
        "word_index['high']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GHmqtyqMs1M",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### DataLoaders and Batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxSY_IpgMs1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(training_sequences), torch.from_numpy(training_labels))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_sequences), torch.from_numpy(val_labels))\n",
        "\n",
        "# dataloaders\n",
        "train_batch_size = 32\n",
        "val_batch_size = 20\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=train_batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSv7wzc1Ms1Q",
        "colab_type": "code",
        "outputId": "0517b2ba-eadf-47ab-e5ee-68935e65ae4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([32, 200])\n",
            "Sample input: \n",
            " tensor([[1.3580e+03, 1.1430e+03, 1.3100e+02,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        [3.2452e+04, 7.0000e+00, 4.8300e+02,  ..., 4.6000e+02, 6.9830e+03,\n",
            "         5.2800e+02],\n",
            "        [3.8161e+04, 4.9440e+03, 6.4000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00],\n",
            "        ...,\n",
            "        [6.2000e+01, 2.0540e+03, 1.0280e+03,  ..., 1.1590e+03, 1.0400e+02,\n",
            "         5.6000e+01],\n",
            "        [6.2000e+01, 2.8070e+03, 3.3000e+01,  ..., 7.0000e+02, 5.0400e+02,\n",
            "         6.2000e+01],\n",
            "        [3.1430e+03, 8.6400e+02, 1.0400e+02,  ..., 2.3270e+03, 2.1610e+03,\n",
            "         5.0800e+02]], dtype=torch.float64)\n",
            "\n",
            "Sample label size:  torch.Size([32])\n",
            "Sample label: \n",
            " tensor([0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ta-v_XrMs1U",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixqhd0tMs1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.shape\n",
        "    emb_layer = nn.Embedding.from_pretrained(torch.from_numpy(weights_matrix))\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size, weights_matrix, hidden_dim, n_layers, drop_prob=0.5, bi=False):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirect = bi\n",
        "        \n",
        "        # define all layers\n",
        "        self.embedding, num_embeddings, embedding_dim = custom_emb_layer(weights_matrix, True)\n",
        "        self.conv1d = nn.Conv1d(100, 256, 5)\n",
        "        self.lstm = nn.LSTM(256, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True, bidirectional=bi)\n",
        "        self.maxpool1d = nn.MaxPool1d(4)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.fc1 = nn.Linear(hidden_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, output_size)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long()\n",
        "        x = self.dropout1(self.embedding(x))\n",
        "        x = x.transpose(1,2).float()\n",
        "        x = self.maxpool1d(self.conv1d(x))\n",
        "        x = x.transpose(1,2)\n",
        "        x, hidden = self.lstm(x, hidden)\n",
        "        x = x.contiguous().view(-1, self.hidden_dim)\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        sig_out = self.sig(self.fc2(x))\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1]\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        if self.bidirect == True:\n",
        "            c = 2\n",
        "        else:\n",
        "            c = 1\n",
        "\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers*c, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers*c, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers*c, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers*c, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUYr14lBMs1c",
        "colab_type": "text"
      },
      "source": [
        "### Instantiate the network\n",
        "\n",
        "\n",
        "* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n",
        "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
        "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgG3V1hRMs1d",
        "colab_type": "code",
        "outputId": "5d7f8f81-87c0-4faf-dd9e-d28b3ba2b67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "output_size = 1\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(output_size, embeddings_matrix, hidden_dim, n_layers, bi=False)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(74077, 100)\n",
            "  (conv1d): Conv1d(100, 256, kernel_size=(5,), stride=(1,))\n",
            "  (lstm): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (maxpool1d): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout1): Dropout(p=0.4, inplace=False)\n",
            "  (dropout2): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rihMYxP6Ms1f",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_gEJLjNMs1k",
        "colab_type": "code",
        "outputId": "5a63db71-865d-47bb-b315-da8a5cb6a58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "# training params\n",
        "epochs = 50 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "print(\"====================TRAINING PROCESS====================\")\n",
        "for e in range(epochs):\n",
        "    t0 = time.time()\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(train_batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        # nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        \n",
        "    # Get validation loss\n",
        "    val_h = net.init_hidden(val_batch_size)\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valid_loader:\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "            if(train_on_gpu):\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            output, val_h = net(inputs, val_h)\n",
        "            val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "            valid_loss += val_loss.item()\n",
        "            equals = torch.round(output) == labels.view(*output.shape)\n",
        "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        \n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    valid_loss = valid_loss/len(valid_loader)\n",
        "    valid_acc = accuracy/len(valid_loader)\n",
        "\n",
        "    net.train()\n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "            \"Step: {}...\".format(counter),\n",
        "            \"Loss: {:.6f}...\".format(train_loss),\n",
        "            \"Val Loss: {:.6f}\".format(valid_loss),\n",
        "           \"Val acc: {:.3f}\".format(valid_acc),\n",
        "           \"Time elapsed: {:.1f}\".format( time.time()-t0))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================TRAINING PROCESS====================\n",
            "Epoch: 1/50... Step: 625... Loss: 0.693197... Val Loss: 0.689331 Val acc: 0.541 Time elapsed: 6.6\n",
            "Epoch: 2/50... Step: 1250... Loss: 0.641000... Val Loss: 0.523590 Val acc: 0.739 Time elapsed: 6.6\n",
            "Epoch: 3/50... Step: 1875... Loss: 0.531877... Val Loss: 0.472397 Val acc: 0.783 Time elapsed: 6.6\n",
            "Epoch: 4/50... Step: 2500... Loss: 0.496419... Val Loss: 0.529168 Val acc: 0.781 Time elapsed: 6.6\n",
            "Epoch: 5/50... Step: 3125... Loss: 0.483490... Val Loss: 0.476830 Val acc: 0.791 Time elapsed: 6.6\n",
            "Epoch: 6/50... Step: 3750... Loss: 0.474553... Val Loss: 0.457054 Val acc: 0.786 Time elapsed: 6.6\n",
            "Epoch: 7/50... Step: 4375... Loss: 0.459142... Val Loss: 0.466897 Val acc: 0.785 Time elapsed: 6.6\n",
            "Epoch: 8/50... Step: 5000... Loss: 0.453548... Val Loss: 0.434779 Val acc: 0.802 Time elapsed: 6.6\n",
            "Epoch: 9/50... Step: 5625... Loss: 0.439901... Val Loss: 0.427160 Val acc: 0.804 Time elapsed: 6.6\n",
            "Epoch: 10/50... Step: 6250... Loss: 0.438985... Val Loss: 0.418977 Val acc: 0.815 Time elapsed: 6.6\n",
            "Epoch: 11/50... Step: 6875... Loss: 0.433020... Val Loss: 0.445402 Val acc: 0.797 Time elapsed: 6.6\n",
            "Epoch: 12/50... Step: 7500... Loss: 0.423097... Val Loss: 0.467206 Val acc: 0.787 Time elapsed: 6.6\n",
            "Epoch: 13/50... Step: 8125... Loss: 0.418270... Val Loss: 0.411451 Val acc: 0.812 Time elapsed: 6.6\n",
            "Epoch: 14/50... Step: 8750... Loss: 0.411341... Val Loss: 0.477978 Val acc: 0.783 Time elapsed: 6.6\n",
            "Epoch: 15/50... Step: 9375... Loss: 0.412201... Val Loss: 0.421751 Val acc: 0.807 Time elapsed: 6.6\n",
            "Epoch: 16/50... Step: 10000... Loss: 0.410911... Val Loss: 0.476130 Val acc: 0.779 Time elapsed: 6.6\n",
            "Epoch: 17/50... Step: 10625... Loss: 0.409506... Val Loss: 0.419097 Val acc: 0.813 Time elapsed: 6.6\n",
            "Epoch: 18/50... Step: 11250... Loss: 0.400817... Val Loss: 0.459448 Val acc: 0.790 Time elapsed: 6.6\n",
            "Epoch: 19/50... Step: 11875... Loss: 0.392625... Val Loss: 0.395209 Val acc: 0.822 Time elapsed: 6.6\n",
            "Epoch: 20/50... Step: 12500... Loss: 0.389130... Val Loss: 0.398526 Val acc: 0.822 Time elapsed: 6.6\n",
            "Epoch: 21/50... Step: 13125... Loss: 0.385246... Val Loss: 0.428090 Val acc: 0.803 Time elapsed: 6.6\n",
            "Epoch: 22/50... Step: 13750... Loss: 0.377916... Val Loss: 0.428079 Val acc: 0.808 Time elapsed: 6.5\n",
            "Epoch: 23/50... Step: 14375... Loss: 0.375713... Val Loss: 0.413529 Val acc: 0.819 Time elapsed: 6.5\n",
            "Epoch: 24/50... Step: 15000... Loss: 0.370275... Val Loss: 0.436379 Val acc: 0.808 Time elapsed: 6.6\n",
            "Epoch: 25/50... Step: 15625... Loss: 0.370254... Val Loss: 0.491788 Val acc: 0.791 Time elapsed: 6.6\n",
            "Epoch: 26/50... Step: 16250... Loss: 0.367425... Val Loss: 0.420940 Val acc: 0.811 Time elapsed: 6.6\n",
            "Epoch: 27/50... Step: 16875... Loss: 0.364139... Val Loss: 0.438282 Val acc: 0.808 Time elapsed: 6.6\n",
            "Epoch: 28/50... Step: 17500... Loss: 0.359871... Val Loss: 0.408847 Val acc: 0.816 Time elapsed: 6.6\n",
            "Epoch: 29/50... Step: 18125... Loss: 0.360062... Val Loss: 0.481721 Val acc: 0.812 Time elapsed: 6.6\n",
            "Epoch: 30/50... Step: 18750... Loss: 0.368004... Val Loss: 0.419287 Val acc: 0.813 Time elapsed: 6.6\n",
            "Epoch: 31/50... Step: 19375... Loss: 0.355435... Val Loss: 0.416397 Val acc: 0.822 Time elapsed: 6.6\n",
            "Epoch: 32/50... Step: 20000... Loss: 0.356268... Val Loss: 0.482322 Val acc: 0.787 Time elapsed: 6.6\n",
            "Epoch: 33/50... Step: 20625... Loss: 0.349757... Val Loss: 0.437938 Val acc: 0.815 Time elapsed: 6.6\n",
            "Epoch: 34/50... Step: 21250... Loss: 0.348802... Val Loss: 0.429071 Val acc: 0.817 Time elapsed: 6.6\n",
            "Epoch: 35/50... Step: 21875... Loss: 0.340343... Val Loss: 0.510578 Val acc: 0.794 Time elapsed: 6.6\n",
            "Epoch: 36/50... Step: 22500... Loss: 0.337302... Val Loss: 0.436918 Val acc: 0.818 Time elapsed: 6.6\n",
            "Epoch: 37/50... Step: 23125... Loss: 0.340123... Val Loss: 0.401699 Val acc: 0.829 Time elapsed: 6.6\n",
            "Epoch: 38/50... Step: 23750... Loss: 0.342224... Val Loss: 0.453645 Val acc: 0.802 Time elapsed: 6.6\n",
            "Epoch: 39/50... Step: 24375... Loss: 0.336398... Val Loss: 0.423125 Val acc: 0.817 Time elapsed: 6.6\n",
            "Epoch: 40/50... Step: 25000... Loss: 0.330718... Val Loss: 0.407463 Val acc: 0.830 Time elapsed: 6.6\n",
            "Epoch: 41/50... Step: 25625... Loss: 0.334257... Val Loss: 0.394184 Val acc: 0.831 Time elapsed: 6.6\n",
            "Epoch: 42/50... Step: 26250... Loss: 0.323694... Val Loss: 0.460516 Val acc: 0.809 Time elapsed: 6.6\n",
            "Epoch: 43/50... Step: 26875... Loss: 0.328633... Val Loss: 0.421165 Val acc: 0.817 Time elapsed: 6.6\n",
            "Epoch: 44/50... Step: 27500... Loss: 0.328530... Val Loss: 0.424399 Val acc: 0.820 Time elapsed: 6.6\n",
            "Epoch: 45/50... Step: 28125... Loss: 0.324612... Val Loss: 0.415296 Val acc: 0.820 Time elapsed: 6.6\n",
            "Epoch: 46/50... Step: 28750... Loss: 0.330128... Val Loss: 0.432970 Val acc: 0.816 Time elapsed: 6.6\n",
            "Epoch: 47/50... Step: 29375... Loss: 0.323469... Val Loss: 0.422716 Val acc: 0.812 Time elapsed: 6.5\n",
            "Epoch: 48/50... Step: 30000... Loss: 0.323081... Val Loss: 0.386397 Val acc: 0.827 Time elapsed: 6.6\n",
            "Epoch: 49/50... Step: 30625... Loss: 0.317426... Val Loss: 0.521283 Val acc: 0.808 Time elapsed: 6.5\n",
            "Epoch: 50/50... Step: 31250... Loss: 0.313026... Val Loss: 0.421821 Val acc: 0.829 Time elapsed: 6.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0ewC8dMMs1o",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVuB6MPiMs1p",
        "colab_type": "code",
        "outputId": "17e184d7-764f-46fb-b240-78cd8a2e72ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(val_batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in valid_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(valid_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.430\n",
            "Test accuracy: 0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI2Tv4C2Ms1r",
        "colab_type": "text"
      },
      "source": [
        "### Inference on a test review\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MykBWNNiMs1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# negative test review\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1vSJQSYa5r3",
        "colab_type": "code",
        "outputId": "fc7bf6ac-21d0-4615-a4d8-4006d9be3b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([word_index[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "# test code and generate tokenized review\n",
        "test_ints = tokenize_review(test_review_neg)\n",
        "print(test_ints)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14, 880, 700, 62, 468, 167, 621, 453, 3069, 64, 62, 952, 26, 340, 547, 346, 700, 223, 506, 621, 64, 14, 142, 453, 611]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eATYWw9LMs1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "    ''' Prints out whether a give review is predicted to be \n",
        "        positive or negative in sentiment, using a trained model.\n",
        "        \n",
        "        params:\n",
        "        net - A trained net \n",
        "        test_review - a review made of normal text and punctuation\n",
        "        sequence_length - the padded length of a review\n",
        "        '''\n",
        "    \n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize review\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    # printing output value, before rounding\n",
        "    print(feature_tensor.shape)\n",
        "    print(output.shape)\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "    \n",
        "    # print custom response\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2MsAhcLMs1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# positive test review\n",
        "test_review_pos = 'This movie had the best acting and the dialogue was so good. I loved it.'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gZQWZGcMs1z",
        "colab_type": "code",
        "outputId": "f57f2d3d-0061-4b0f-ac5c-7eed24d6e792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# call function\n",
        "# try negative and positive reviews!\n",
        "seq_length=200\n",
        "predict(net, test_review_neg, seq_length)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 200])\n",
            "torch.Size([1])\n",
            "Prediction value, pre-rounding: 0.001398\n",
            "Negative review detected.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}